{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d229c2b5",
   "metadata": {},
   "source": [
    "### Resume Parser\n",
    "This notebook presents an end-to-end Resume Parsing Pipeline that automatically extracts structured information - name, email, and skills - from resumes in PDF and Word formats.\n",
    "The solution integrates both rule-based NLP and an optional LLM-based extraction method, offering a balance between cost-efficiency and robustness.\n",
    "\n",
    "#### Key components include:\n",
    "\n",
    "- Dataset generation: realistic sample resumes and labeled ground truth for evaluation.\n",
    "\n",
    "- Parsing logic: deterministic regex and keyword-based extraction, complemented by LLM parsing for unstructured or noisy layouts.\n",
    "\n",
    "- Hybrid strategy: confidence-driven combination of rule and LLM outputs to maximize accuracy and recall.\n",
    "\n",
    "- Evaluation: quantitative metrics (accuracy, precision, recall, F1) for objective performance comparison.\n",
    "\n",
    "- Reproducibility: pinned dependencies, clean modular design, and environment setup for seamless execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1915d267",
   "metadata": {},
   "source": [
    "## 0) Reproducible Setup\n",
    "In this cell, we install all required dependencies and create a requirements.txt file.\n",
    "This ensures the notebook is fully reproducible in any environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd242c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Wrote requirements.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\vvkma\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\vvkma\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\vvkma\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\vvkma\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\vvkma\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\vvkma\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install --user -q     pdfplumber==0.11.4     python-docx==1.1.2     reportlab==4.2.5     pandas==2.2.2     numpy==1.26.4     tabulate==0.9.0     tenacity==8.4.2     openai==1.43.0\n",
    "\n",
    "reqs = \"\"\"pdfplumber==0.11.4\n",
    "python-docx==1.1.2\n",
    "reportlab==4.2.5\n",
    "pandas==2.2.2\n",
    "numpy==1.26.4\n",
    "tabulate==0.9.0\n",
    "tenacity==8.4.2\n",
    "openai==1.43.0\n",
    "\"\"\"\n",
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    f.write(reqs)\n",
    "print(\"Wrote requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841561f7",
   "metadata": {},
   "source": [
    "## 1) Configuration\n",
    "Here we define constants, folder paths, and the canonical list of skills to match during parsing.\n",
    "These can be modified or extended for other domains or datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abd9120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder: ./data/resumes_dataset\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "random.seed(42)\n",
    "\n",
    "DATA_DIR = \"./data/resumes_dataset\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(\"Data folder:\", DATA_DIR)\n",
    "\n",
    "CANONICAL_SKILLS = [\n",
    "    \"Python\",\"R\",\"SQL\",\"Machine Learning\",\"Deep Learning\",\"NLP\",\"LLM\",\"Computer Vision\",\"Statistics\",\n",
    "    \"Data Engineering\",\"Spark\",\"Databricks\",\"Azure\",\"AWS\",\"GCP\",\"Docker\",\"Kubernetes\",\"Git\",\n",
    "    \"Tableau\",\"Power BI\",\"Pandas\",\"NumPy\",\"Scikit-learn\",\"PyTorch\",\"TensorFlow\",\"REST\",\"GraphQL\",\"Airflow\",\"Kafka\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba202e22",
   "metadata": {},
   "source": [
    "## 2) Rule-based Parser\n",
    "In this section, we define the logic for parsing resumes using traditional NLP and regex-based methods.\n",
    "This approach does not require any machine learning model or LLM, making it lightweight, fast, and interpretable.\n",
    " \n",
    "Key Components:\n",
    "- Text extraction from PDFs and Word (.docx) files\n",
    "- Regular expression–based extraction of name and email\n",
    "- Keyword matching for skills using a canonical skill list\n",
    "- Simple text normalization and pattern search functions\n",
    "\n",
    "These functions together create a baseline parser that can be evaluated against more advanced (LLM-based) methods later in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcae5441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vvkma\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import re, json, pdfplumber\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "# ------------------------------ REGEX PATTERNS ------------------------------\n",
    "# EMAIL_RE: matches most valid email addresses (user@domain.tld)\n",
    "EMAIL_RE = re.compile(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\")\n",
    "\n",
    "# NAME_LINE_RE: detects lines that look like a name (e.g., \"Jane Doe\" or \"Name: John Smith\")\n",
    "# The pattern allows 2–4 capitalized words optionally prefixed by \"Name:\"\n",
    "NAME_LINE_RE = re.compile(r\"^(?:Name\\s*:\\s*)?([A-Z][a-zA-Z]+(?:\\s+[A-Z][a-zA-Z]+){1,3})$\")\n",
    "\n",
    "# ------------------------------ TEXT NORMALIZATION ------------------------------\n",
    "def normalize_text(t: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize extracted text by collapsing multiple whitespaces/newlines into single spaces.\n",
    "    This ensures consistent downstream regex matching.\n",
    "    \"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", t).strip()\n",
    "\n",
    "# ------------------------------ FILE READING HELPERS ------------------------------\n",
    "def read_pdf(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from all pages of a PDF file using pdfplumber.\n",
    "    Returns a concatenated string representing the entire document.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        for p in pdf.pages:\n",
    "            t = p.extract_text() or \"\"\n",
    "            if t:\n",
    "                out.append(t)\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "def read_docx(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from a Word (.docx) file using python-docx.\n",
    "    Joins non-empty paragraph texts with newline separators.\n",
    "    \"\"\"\n",
    "    doc = Document(path)\n",
    "    lines = [p.text for p in doc.paragraphs if p.text and p.text.strip()]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def read_file_text(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Automatically determines file type (PDF or DOCX) and routes\n",
    "    to the appropriate text extraction function.\n",
    "    Raises an error for unsupported extensions.\n",
    "    \"\"\"\n",
    "    p = path.lower()\n",
    "    if p.endswith(\".pdf\"):\n",
    "        return read_pdf(path)\n",
    "    if p.endswith(\".docx\"):\n",
    "        return read_docx(path)\n",
    "    raise ValueError(f\"Unsupported file: {path}\")\n",
    "\n",
    "# ------------------------------ FIELD EXTRACTION FUNCTIONS ------------------------------\n",
    "def extract_email(text: str):\n",
    "    \"\"\"\n",
    "    Finds the first valid email address in the resume text.\n",
    "    Returns None if no email is found.\n",
    "    \"\"\"\n",
    "    m = EMAIL_RE.search(text)\n",
    "    return m.group(0) if m else None\n",
    "\n",
    "def extract_name(text: str):\n",
    "    \"\"\"\n",
    "    Attempts to extract a person's full name from the resume.\n",
    "    Strategy:\n",
    "      - Check the first few lines for a 'Name:' prefix or proper capitalization pattern.\n",
    "      - Fallback to searching the entire text for 'Name: <First Last>'.\n",
    "    \"\"\"\n",
    "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
    "    for l in lines[:8]:  # Names usually appear near the top of the document\n",
    "        m = NAME_LINE_RE.match(l)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "    # Fallback: if not found, look for \"Name: ...\" anywhere in text\n",
    "    m2 = re.search(r\"Name\\s*:\\s*([A-Z][a-zA-Z]+(?:\\s+[A-Z][a-zA-Z]+){1,3})\", text)\n",
    "    return m2.group(1) if m2 else None\n",
    "\n",
    "def skill_match(text: str, skills: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Matches predefined canonical skills within the resume text (case-insensitive).\n",
    "    Each skill is matched using word boundaries to avoid false positives (e.g., \"SQL\" in \"sequel\").\n",
    "    Duplicates are removed while preserving order.\n",
    "    \"\"\"\n",
    "    found, seen, out = [], set(), []\n",
    "    for sk in skills:\n",
    "        if re.search(rf\"(?<!\\w){re.escape(sk)}(?!\\w)\", text, flags=re.IGNORECASE):\n",
    "            if sk.lower() not in seen:\n",
    "                out.append(sk)\n",
    "                seen.add(sk.lower())\n",
    "    return out\n",
    "\n",
    "# ------------------------------ MAIN PARSER FUNCTION ------------------------------\n",
    "def parse_resume_text(text: str) -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Combines all rule-based extraction logic into a single function.\n",
    "    Steps:\n",
    "      1. Normalize text for consistency.\n",
    "      2. Extract name using capitalization and 'Name:' pattern.\n",
    "      3. Extract email using regex.\n",
    "      4. Match skills from a predefined canonical list.\n",
    "    Returns:\n",
    "      dict(name, email, skills)\n",
    "    \"\"\"\n",
    "    t = normalize_text(text)\n",
    "    return {\n",
    "        \"name\": extract_name(t),\n",
    "        \"email\": extract_email(t),\n",
    "        \"skills\": skill_match(t, CANONICAL_SKILLS)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8276a4",
   "metadata": {},
   "source": [
    "## 3) Run Rule-based Parser on all files\n",
    "In this section, we apply the rule-based parser to every resume in our dataset.\n",
    "Each resume (PDF or Word) is read, parsed, and the extracted fields (name, email, skills) are stored in a structured JSON format for later evaluation.\n",
    "\n",
    "Key steps:\n",
    "1. Collect all file paths from the dataset directory.\n",
    "2. Parse each file using `parse_resume_text()`.\n",
    "3. Store results in a dictionary keyed by the candidate’s file name.\n",
    "4. Save results to a JSON file (`parsed_results.json`) for reproducibility.\n",
    "5. Display a summary table of parsed outputs using pandas for easy review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd387b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rule-based results → ./data/resumes_dataset\\parsed_results.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arjun_mehta</td>\n",
       "      <td></td>\n",
       "      <td>arjun.mehta@outlook.com</td>\n",
       "      <td>[Machine Learning, Deep Learning, Computer Vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fatima_khan</td>\n",
       "      <td></td>\n",
       "      <td>fatima.khan@company.com</td>\n",
       "      <td>[Python, Machine Learning, Data Engineering, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jane_doe</td>\n",
       "      <td></td>\n",
       "      <td>jane.doe@gmail.com</td>\n",
       "      <td>[Python, SQL, Machine Learning, LLM, Statistic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>liu_wei</td>\n",
       "      <td></td>\n",
       "      <td>liu.wei@sample.org</td>\n",
       "      <td>[Data Engineering, Spark, Databricks, REST, Ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maria_garcia</td>\n",
       "      <td></td>\n",
       "      <td>maria.garcia@proton.me</td>\n",
       "      <td>[Python, NLP, LLM, GCP, Kubernetes, Tableau, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>owen_smith</td>\n",
       "      <td></td>\n",
       "      <td>owen.smith@yahoo.com</td>\n",
       "      <td>[SQL, Statistics, Azure, Tableau, Power BI]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person name                    email  \\\n",
       "0   arjun_mehta       arjun.mehta@outlook.com   \n",
       "1   fatima_khan       fatima.khan@company.com   \n",
       "2      jane_doe            jane.doe@gmail.com   \n",
       "3       liu_wei            liu.wei@sample.org   \n",
       "4  maria_garcia        maria.garcia@proton.me   \n",
       "5    owen_smith          owen.smith@yahoo.com   \n",
       "\n",
       "                                              skills  \n",
       "0  [Machine Learning, Deep Learning, Computer Vis...  \n",
       "1  [Python, Machine Learning, Data Engineering, D...  \n",
       "2  [Python, SQL, Machine Learning, LLM, Statistic...  \n",
       "3  [Data Engineering, Spark, Databricks, REST, Ai...  \n",
       "4  [Python, NLP, LLM, GCP, Kubernetes, Tableau, T...  \n",
       "5        [SQL, Statistics, Azure, Tableau, Power BI]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, json\n",
    "from IPython.display import display\n",
    "\n",
    "# Step 1: Collect all resume file paths (both PDF and DOCX)\n",
    "files = [\n",
    "    os.path.join(DATA_DIR, f)\n",
    "    for f in os.listdir(DATA_DIR)\n",
    "    if f.lower().endswith((\".pdf\", \".docx\"))\n",
    "]\n",
    "\n",
    "# Step 2: Initialize an empty dictionary to store parsed outputs\n",
    "preds = {}\n",
    "\n",
    "# Step 3: Loop through each resume, extract text, and parse using our rule-based function\n",
    "for fp in sorted(files):\n",
    "    base = os.path.splitext(os.path.basename(fp))[0]  # e.g., \"jane_doe\"\n",
    "    # Parse resume text and store structured output\n",
    "    preds.setdefault(base, parse_resume_text(read_file_text(fp)))\n",
    "\n",
    "# Step 4: Save the parsed results to disk as JSON (for reproducibility & evaluation)\n",
    "out_json = os.path.join(DATA_DIR, \"parsed_results.json\")\n",
    "with open(out_json, \"w\") as f:\n",
    "    json.dump(preds, f, indent=2)\n",
    "print(f\"Saved rule-based results → {out_json}\")\n",
    "\n",
    "# Step 5: Display parsed results in a readable DataFrame\n",
    "# Each row = one resume, columns = extracted fields (name, email, skills)\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        [{\"person\": k, **v} for k, v in preds.items()]\n",
    "    ).fillna(\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c8888",
   "metadata": {},
   "source": [
    "## 4) LLM Extraction (OpenAI) \n",
    "In this section, we parse each resume with an OpenAI foundation model to extract:\n",
    "  { \"name\": string, \"email\": string, \"skills\": [string, ...] }\n",
    "\n",
    "Why?\n",
    "- LLMs are often more robust to varied layouts, inconsistent headings, and noisy text.\n",
    "- We strictly constrain the output to JSON for reliable downstream processing.\n",
    "\n",
    "Design:\n",
    "- Version-agnostic client: supports both the new 'openai' SDK (v1.x with OpenAI()) and\n",
    "  the legacy SDK (v0.27/0.28 with openai.ChatCompletion).\n",
    "- Uses environment variable OPENAI_API_KEY (no keys in code).\n",
    "- Retries with exponential backoff on transient errors.\n",
    "- Skips gracefully if no API key is set (so the notebook still runs end-to-end).\n",
    "\n",
    "Output:\n",
    "- Saves LLM results to: data/resumes_dataset/parsed_results_llm.json\n",
    "- You can compare these to the rule-based baseline in the evaluation section.\n",
    "\n",
    "#### Rationale for Model Choice (gpt-4o-mini)\n",
    "\n",
    "- The LLM component uses gpt-4o-mini, a lightweight version of GPT-4 optimized for speed and affordability while retaining strong reasoning and language understanding capabilities.\n",
    "\n",
    "This model was selected based on three key factors:\n",
    "\n",
    "- Performance–Cost Balance: gpt-4o-mini achieves performance comparable to GPT-4 on general reasoning and information extraction tasks but at ~15–20× lower cost and ~2–3× faster latency.This makes it suitable for large-scale resume parsing workloads or batch inference pipelines where cost efficiency is crucial.\n",
    "\n",
    "- Empirical Benchmark Results (MTEB Leaderboard – 2024):On the Massive Text Embedding Benchmark (MTEB), which evaluates retrieval, clustering, classification, and summarization tasks, OpenAI’s GPT-4-class models rank near the top across most categories. Specifically:GPT-4 embeddings / GPT-4o models score in the mid-70s average MTEB score range — outperforming older open models like text-embedding-ada-002 (61.0) or BGE-base-en (63.2).This indicates that even the mini variant captures rich semantic structure and maintains strong text understanding needed for parsing and field extraction.\n",
    "\n",
    "- Reproducibility and Accessibility: gpt-4o-mini is available via OpenAI’s API without fine-tuning requirements, ensuring consistent, reproducible results.Its lower compute footprint allows easy experimentation within free-tier or low-budget environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c48b10ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM available: True\n",
      " Saved LLM results → ./data/resumes_dataset\\parsed_results_llm.json\n"
     ]
    }
   ],
   "source": [
    "import os, json, re\n",
    "from typing import Dict\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "\n",
    "# Read API key from environment.  \n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Detect and configure the OpenAI SDK in a version-agnostic way.\n",
    "# Prefer the new SDK. If import fails, fall back to legacy openai.ChatCompletion.\n",
    "if OPENAI_API_KEY:\n",
    "    try:\n",
    "        from openai import OpenAI                               # New SDK (v1.x)\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        USE_NEW = hasattr(client, \"chat\") and hasattr(client.chat, \"completions\")\n",
    "        USE_LEGACY = False\n",
    "    except Exception:\n",
    "        import openai                                           # Legacy SDK (v0.27/0.28)\n",
    "        openai.api_key = OPENAI_API_KEY\n",
    "        client = None\n",
    "        USE_NEW = False\n",
    "        USE_LEGACY = hasattr(openai, \"ChatCompletion\")\n",
    "else:\n",
    "    client = None\n",
    "    USE_NEW = False\n",
    "    USE_LEGACY = False\n",
    "\n",
    "# System instructions for the model. Use triple double-quotes to avoid quote escaping issues.\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert resume parser.\n",
    "Extract exactly this JSON:\n",
    "{\n",
    "  \"name\": \"string\",\n",
    "  \"email\": \"string\",\n",
    "  \"skills\": [\"string\", ...]\n",
    "}\n",
    "Rules:\n",
    "- Output pure JSON only.\n",
    "- If missing, set name/email to null and skills to [].\n",
    "- Do not infer unstated skills.\n",
    "\"\"\"\n",
    "\n",
    "# Chosen model (good price/performance). You can swap to a different chat model if desired.\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "def _postprocess(d: Dict[str, object]) -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Normalize/clean the raw JSON returned by the LLM:\n",
    "      - guarantee keys exist,\n",
    "      - trim whitespace on strings,\n",
    "      - coerce skills to a list of strings,\n",
    "      - drop empties.\n",
    "    \"\"\"\n",
    "    name  = d.get(\"name\")\n",
    "    email = d.get(\"email\")\n",
    "    skills = d.get(\"skills\") or []\n",
    "\n",
    "    if isinstance(name, str):\n",
    "        name = name.strip()\n",
    "    if isinstance(email, str):\n",
    "        email = email.strip()\n",
    "    if not isinstance(skills, list):\n",
    "        skills = []\n",
    "    skills = [str(s).strip() for s in skills if str(s).strip()]\n",
    "\n",
    "    return {\"name\": name, \"email\": email, \"skills\": skills}\n",
    "\n",
    "def _parse_json(text: str) -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Parse the model response as JSON.\n",
    "    If the model included extra text, extract the first {...} block as a fallback.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        m = re.search(r\"\\{[\\s\\S]*\\}\", text)\n",
    "        if not m:\n",
    "            raise\n",
    "        return json.loads(m.group(0))\n",
    "\n",
    "@retry(\n",
    "    wait=wait_exponential(multiplier=1, min=1, max=8),   # exponential backoff\n",
    "    stop=stop_after_attempt(3),                           # up to 3 tries\n",
    "    retry=retry_if_exception_type(Exception),             # retry on generic exceptions\n",
    ")\n",
    "def llm_extract(text: str) -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Call the LLM to extract the target JSON schema from raw resume text.\n",
    "    Implementation is SDK-version aware (new vs legacy).\n",
    "    \"\"\"\n",
    "    # Safety truncation: avoid overly long prompts hitting token limits.\n",
    "    user = text[:120_000]\n",
    "\n",
    "    if USE_NEW:\n",
    "        # New SDK path\n",
    "        resp = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"},  # request strict JSON\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": user},\n",
    "            ],\n",
    "        )\n",
    "        content = resp.choices[0].message.content\n",
    "\n",
    "    elif USE_LEGACY:\n",
    "        # Legacy SDK path\n",
    "        import openai\n",
    "        resp = openai.ChatCompletion.create(\n",
    "            model=LLM_MODEL,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": user},\n",
    "            ],\n",
    "        )\n",
    "        content = resp[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    else:\n",
    "        # No API key or no compatible SDK → instruct caller to skip LLM stage\n",
    "        raise RuntimeError(\"OPENAI_API_KEY not set or SDK unavailable.\")\n",
    "\n",
    "    return _postprocess(_parse_json(content))\n",
    "\n",
    "# Flag used by the rest of the notebook to decide whether to run LLM steps\n",
    "llm_available = bool(OPENAI_API_KEY) and (USE_NEW or USE_LEGACY)\n",
    "print(\"LLM available:\", llm_available)\n",
    "\n",
    "# Run LLM extraction if available; otherwise skip gracefully.\n",
    "llm_preds = {}\n",
    "if llm_available:\n",
    "    # 'files' is prepared earlier in the pipeline; each item is a path to a PDF/DOCX.\n",
    "    # We also rely on read_file_text() from the rule-based helpers to get raw text.\n",
    "    for fp in sorted(files):\n",
    "        base = os.path.splitext(os.path.basename(fp))[0]\n",
    "        if base in llm_preds:                # avoid duplicate work (e.g., .pdf and .docx for same person)\n",
    "            continue\n",
    "        llm_preds[base] = llm_extract(read_file_text(fp))\n",
    "\n",
    "    # Persist results for evaluation and for the hybrid step\n",
    "    out_llm = os.path.join(DATA_DIR, \"parsed_results_llm.json\")\n",
    "    with open(out_llm, \"w\") as f:\n",
    "        json.dump(llm_preds, f, indent=2)\n",
    "    print(f\" Saved LLM results → {out_llm}\")\n",
    "else:\n",
    "    print(\"Skipping LLM extraction (no key).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e04904",
   "metadata": {},
   "source": [
    "## 5) Hybrid strategy\n",
    "Goal:\n",
    "Combine the strengths of the fast rule-based parser with the robustness of the LLM.\n",
    "\n",
    "Design:\n",
    "- Use the RULE-BASED result when we are \"confident\" (simple, cheap, deterministic).\n",
    "- If confidence is LOW (e.g., missing name/email or too few skills), FALL BACK to the LLM.\n",
    "- Merge skills as the UNION (deduped, order-preserving) to maximize recall without losing precision.\n",
    "\n",
    "Why this heuristic?\n",
    "- Name/email extraction is critical: if either is missing, rules likely failed → rely on LLM.\n",
    "- Very short skill lists often indicate parsing missed content sections (e.g., PDF layout issues).\n",
    "\n",
    "Outputs:\n",
    "- Saves: data/resumes_dataset/parsed_results_hybrid.json\n",
    "- Preview: a DataFrame showing person, name, email, and skill list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11b560d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Hybrid results → ./data/resumes_dataset\\parsed_results_hybrid.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arjun_mehta</td>\n",
       "      <td>Arjun Mehta</td>\n",
       "      <td>arjun.mehta@outlook.com</td>\n",
       "      <td>[Machine Learning, Deep Learning, Computer Vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fatima_khan</td>\n",
       "      <td>Fatima Khan</td>\n",
       "      <td>fatima.khan@company.com</td>\n",
       "      <td>[Python, Machine Learning, Data Engineering, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jane_doe</td>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>jane.doe@gmail.com</td>\n",
       "      <td>[Python, SQL, Machine Learning, LLM, Statistic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>liu_wei</td>\n",
       "      <td>Liu Wei</td>\n",
       "      <td>liu.wei@sample.org</td>\n",
       "      <td>[Data Engineering, Spark, Databricks, REST, Ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maria_garcia</td>\n",
       "      <td>Maria Garcia</td>\n",
       "      <td>maria.garcia@proton.me</td>\n",
       "      <td>[Python, NLP, LLM, GCP, Kubernetes, Tableau, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>owen_smith</td>\n",
       "      <td>Owen Smith</td>\n",
       "      <td>owen.smith@yahoo.com</td>\n",
       "      <td>[SQL, Statistics, Azure, Tableau, Power BI, Da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person          name                    email  \\\n",
       "0   arjun_mehta   Arjun Mehta  arjun.mehta@outlook.com   \n",
       "1   fatima_khan   Fatima Khan  fatima.khan@company.com   \n",
       "2      jane_doe      Jane Doe       jane.doe@gmail.com   \n",
       "3       liu_wei       Liu Wei       liu.wei@sample.org   \n",
       "4  maria_garcia  Maria Garcia   maria.garcia@proton.me   \n",
       "5    owen_smith    Owen Smith     owen.smith@yahoo.com   \n",
       "\n",
       "                                              skills  \n",
       "0  [Machine Learning, Deep Learning, Computer Vis...  \n",
       "1  [Python, Machine Learning, Data Engineering, D...  \n",
       "2  [Python, SQL, Machine Learning, LLM, Statistic...  \n",
       "3  [Data Engineering, Spark, Databricks, REST, Ai...  \n",
       "4  [Python, NLP, LLM, GCP, Kubernetes, Tableau, T...  \n",
       "5  [SQL, Statistics, Azure, Tableau, Power BI, Da...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, pandas as pd\n",
    "\n",
    "def low_conf(x: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Simple confidence check for rule-based output.\n",
    "    Returns True if the result looks incomplete and should defer to the LLM.\n",
    "    \"\"\"\n",
    "    return (not x) or (not x.get(\"name\")) or (not x.get(\"email\")) or (len(x.get(\"skills\", [])) < 2)\n",
    "\n",
    "def dedupe(seq):\n",
    "    \"\"\"\n",
    "    Deduplicate case-insensitively while preserving order.\n",
    "    Useful when unioning skills from rule-based and LLM outputs.\n",
    "    \"\"\"\n",
    "    seen, out = set(), []\n",
    "    for s in seq:\n",
    "        k = str(s).lower().strip()\n",
    "        if k and k not in seen:\n",
    "            out.append(str(s).strip())\n",
    "            seen.add(k)\n",
    "    return out\n",
    "\n",
    "# Load rule-based predictions (required)\n",
    "rule_path = os.path.join(DATA_DIR, \"parsed_results.json\")\n",
    "rule = json.load(open(rule_path))\n",
    "\n",
    "# Load LLM predictions if available (optional)\n",
    "llm_path = os.path.join(DATA_DIR, \"parsed_results_llm.json\")\n",
    "llm = json.load(open(llm_path)) if os.path.exists(llm_path) else {}\n",
    "\n",
    "hybrid = {}\n",
    "\n",
    "# Iterate over the union of people present in either rules or LLM outputs\n",
    "for person in sorted(set(list(rule.keys()) + list(llm.keys()))):\n",
    "    r = rule.get(person, {})\n",
    "    l = llm.get(person, {})\n",
    "\n",
    "    if low_conf(r) and l:\n",
    "        # Low confidence in rules → trust LLM for critical fields, union skills\n",
    "        name  = l.get(\"name\")  or r.get(\"name\")\n",
    "        email = l.get(\"email\") or r.get(\"email\")\n",
    "        skills = dedupe((r.get(\"skills\", []) or []) + (l.get(\"skills\", []) or []))\n",
    "    else:\n",
    "        # Rules look fine → keep rule-based name/email, still union skills to improve recall\n",
    "        name  = r.get(\"name\")  or l.get(\"name\")\n",
    "        email = r.get(\"email\") or l.get(\"email\")\n",
    "        skills = dedupe((r.get(\"skills\", []) or []) + (l.get(\"skills\", []) or []))\n",
    "\n",
    "    hybrid[person] = {\"name\": name, \"email\": email, \"skills\": skills}\n",
    "\n",
    "# Persist merged output for evaluation/inspection\n",
    "out_h = os.path.join(DATA_DIR, \"parsed_results_hybrid.json\")\n",
    "with open(out_h, \"w\") as f:\n",
    "    json.dump(hybrid, f, indent=2)\n",
    "\n",
    "print(f\"Saved Hybrid results → {out_h}\")\n",
    "\n",
    "# Preview as a table\n",
    "pd.DataFrame([{\"person\": k, **v} for k, v in hybrid.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf22af7c",
   "metadata": {},
   "source": [
    "## 6) Evaluation\n",
    "What we measure and why:\n",
    "- Name accuracy: exact (case-insensitive) match to the ground truth.\n",
    "- Email accuracy: exact (case-sensitive) match to the ground truth.\n",
    "- Skills: per-resume Precision, Recall, and F1 (set-based, case-insensitive).\n",
    "\n",
    "Notes:\n",
    "- We compute macro-averages over resumes for skills (i.e., average of per-resume metrics).\n",
    "- This is appropriate because each resume is a distinct “document” classification task.\n",
    "- We evaluate three systems:\n",
    "    1) Rule-based baseline\n",
    "    2) LLM-only\n",
    "    3) Hybrid (rules first, LLM fallback + union of skills)\n",
    "\n",
    "Outputs:\n",
    "- Overall summary tables for each system.\n",
    "- Per-resume tables to inspect TP/FP/FN sources of error (optional toggle below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b66fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Rule-based — Overall Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_accuracy</th>\n",
       "      <th>email_accuracy</th>\n",
       "      <th>skills_macro_precision</th>\n",
       "      <th>skills_macro_recall</th>\n",
       "      <th>skills_macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_accuracy  email_accuracy  skills_macro_precision  skills_macro_recall  \\\n",
       "0            0.0             1.0                   0.833                0.609   \n",
       "\n",
       "   skills_macro_f1  \n",
       "0            0.694  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-Resume:\n",
      "| person       | name_ok   | email_ok   |     P |     R |    F1 |\n",
      "|--------------|-----------|------------|-------|-------|-------|\n",
      "| jane_doe     | False     | True       | 0.818 | 0.9   | 0.857 |\n",
      "| arjun_mehta  | False     | True       | 0.75  | 0.6   | 0.667 |\n",
      "| maria_garcia | False     | True       | 0.714 | 0.5   | 0.588 |\n",
      "| liu_wei      | False     | True       | 1     | 0.6   | 0.75  |\n",
      "| owen_smith   | False     | True       | 1     | 0.556 | 0.714 |\n",
      "| fatima_khan  | False     | True       | 0.714 | 0.5   | 0.588 |\n",
      "### LLM-only — Overall Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_accuracy</th>\n",
       "      <th>email_accuracy</th>\n",
       "      <th>skills_macro_precision</th>\n",
       "      <th>skills_macro_recall</th>\n",
       "      <th>skills_macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_accuracy  email_accuracy  skills_macro_precision  skills_macro_recall  \\\n",
       "0            1.0             1.0                     1.0                  1.0   \n",
       "\n",
       "   skills_macro_f1  \n",
       "0              1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-Resume:\n",
      "| person       | name_ok   | email_ok   |   P |   R |   F1 |\n",
      "|--------------|-----------|------------|-----|-----|------|\n",
      "| jane_doe     | True      | True       |   1 |   1 |    1 |\n",
      "| arjun_mehta  | True      | True       |   1 |   1 |    1 |\n",
      "| maria_garcia | True      | True       |   1 |   1 |    1 |\n",
      "| liu_wei      | True      | True       |   1 |   1 |    1 |\n",
      "| owen_smith   | True      | True       |   1 |   1 |    1 |\n",
      "| fatima_khan  | True      | True       |   1 |   1 |    1 |\n",
      "### Hybrid — Overall Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_accuracy</th>\n",
       "      <th>email_accuracy</th>\n",
       "      <th>skills_macro_precision</th>\n",
       "      <th>skills_macro_recall</th>\n",
       "      <th>skills_macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_accuracy  email_accuracy  skills_macro_precision  skills_macro_recall  \\\n",
       "0            1.0             1.0                   0.889                  1.0   \n",
       "\n",
       "   skills_macro_f1  \n",
       "0            0.939  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-Resume:\n",
      "| person       | name_ok   | email_ok   |     P |   R |    F1 |\n",
      "|--------------|-----------|------------|-------|-----|-------|\n",
      "| jane_doe     | True      | True       | 0.833 |   1 | 0.909 |\n",
      "| arjun_mehta  | True      | True       | 0.833 |   1 | 0.909 |\n",
      "| maria_garcia | True      | True       | 0.833 |   1 | 0.909 |\n",
      "| liu_wei      | True      | True       | 1     |   1 | 1     |\n",
      "| owen_smith   | True      | True       | 1     |   1 | 1     |\n",
      "| fatima_khan  | True      | True       | 0.833 |   1 | 0.909 |\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, json, os\n",
    "from tabulate import tabulate\n",
    "\n",
    "def evaluate(results_path, label):\n",
    "    \"\"\"\n",
    "    Evaluate one system's predictions against ground truth.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    results_path : str\n",
    "        Path to JSON file with predictions: { person_key: {\"name\":..., \"email\":..., \"skills\":[...]}, ... }\n",
    "    label : str\n",
    "        Name of the system (for printing).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (df, summary)\n",
    "      df      : per-resume DataFrame with name/email correctness and skills P/R/F1\n",
    "      summary : single-row DataFrame with macro-averaged metrics\n",
    "    \"\"\"\n",
    "    gt_path = os.path.join(DATA_DIR, \"ground_truth.json\")\n",
    "\n",
    "    # Verify required files exist; if not, skip gracefully\n",
    "    if not (os.path.exists(gt_path) and os.path.exists(results_path)):\n",
    "        print(f\"Skipping {label}: missing files.\")\n",
    "        return None, None\n",
    "\n",
    "    # Load ground truth and predictions\n",
    "    gold  = json.load(open(gt_path))\n",
    "    preds = json.load(open(results_path))\n",
    "\n",
    "    # Helper: case-insensitive equality (used for names)\n",
    "    def eq_ci(a, b):\n",
    "        return bool(a) and bool(b) and a.strip().lower() == b.strip().lower()\n",
    "\n",
    "    # Helper: per-resume Precision/Recall/F1 for skills (case-insensitive set overlap)\n",
    "    def prf1(pred, gold):\n",
    "        ps = set([x.lower() for x in pred])\n",
    "        gs = set([x.lower() for x in gold])\n",
    "        tp = len(ps & gs)\n",
    "        fp = len(ps - gs)\n",
    "        fn = len(gs - ps)\n",
    "        P = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        R = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        F1 = 2 * P * R / (P + R) if (P + R) > 0 else 0.0\n",
    "        return P, R, F1\n",
    "\n",
    "    rows, nh, eh = [], [], []\n",
    "\n",
    "    # Iterate over each person in ground truth (missing preds default to empty fields)\n",
    "    for person, g in gold.items():\n",
    "        p = preds.get(person, {\"name\": None, \"email\": None, \"skills\": []})\n",
    "\n",
    "        # Name accuracy: case-insensitive exact match\n",
    "        n_ok = eq_ci(p.get(\"name\"), g[\"name\"])\n",
    "        nh.append(1.0 if n_ok else 0.0)\n",
    "\n",
    "        # Email accuracy: typical practice is case-sensitive exact match\n",
    "        e_ok = p.get(\"email\") == g[\"email\"]\n",
    "        eh.append(1.0 if e_ok else 0.0)\n",
    "\n",
    "        # Skills metrics (per resume)\n",
    "        P, R, F1 = prf1(p.get(\"skills\", []), g[\"skills\"])\n",
    "\n",
    "        rows.append({\n",
    "            \"person\": person,\n",
    "            \"name_ok\": n_ok,\n",
    "            \"email_ok\": e_ok,\n",
    "            \"P\": round(P, 3),\n",
    "            \"R\": round(R, 3),\n",
    "            \"F1\": round(F1, 3),\n",
    "        })\n",
    "\n",
    "    # Per-resume table\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Macro-averaged summary across resumes\n",
    "    summary = pd.DataFrame([{\n",
    "        \"name_accuracy\": round(float(np.mean(nh)), 3),\n",
    "        \"email_accuracy\": round(float(np.mean(eh)), 3),\n",
    "        \"skills_macro_precision\": round(float(df[\"P\"].mean()), 3),\n",
    "        \"skills_macro_recall\": round(float(df[\"R\"].mean()), 3),\n",
    "        \"skills_macro_f1\": round(float(df[\"F1\"].mean()), 3),\n",
    "    }])\n",
    "\n",
    "    # Display results\n",
    "    print(f\"### {label} — Overall Metrics\")\n",
    "    display(summary)\n",
    "    print(\"\\nPer-Resume:\")\n",
    "    print(tabulate(df, headers=\"keys\", tablefmt=\"github\", showindex=False))\n",
    "\n",
    "    return df, summary\n",
    "\n",
    "# Evaluate Rule-based, LLM-only, and Hybrid results side by side\n",
    "rule_df, _ = evaluate(os.path.join(DATA_DIR, \"parsed_results.json\"), \"Rule-based\")\n",
    "llm_df,  _ = evaluate(os.path.join(DATA_DIR, \"parsed_results_llm.json\"), \"LLM-only\")\n",
    "hyb_df,  _ = evaluate(os.path.join(DATA_DIR, \"parsed_results_hybrid.json\"), \"Hybrid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
